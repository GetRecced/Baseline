{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes as input a .json review file and outputs 2 .json files with train and test data, such that all the users and items in test are present in train too (not guaranteed for items, but usually true for low k, as there are far fewer items than users). \n",
    "\n",
    "The first k rows are moved from train to test for each user (default=1). Takes a couple of minutes to run for 700k reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats.stats import pearsonr \n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "k=1 #take k rows from each user and put in test set\n",
    "m=3 #after cutting, remove items with <m rows left\n",
    "\n",
    "filename = '../reviews_Apps_for_Android_5.json'\n",
    "start_index = 0\n",
    "end_index = 10000 #set to None for reading the entire file\n",
    "jsonFile = True #JSON file output by default\n",
    "\n",
    "# load the data, keep only selected columns\n",
    "# Read the file using super fast Pandas.read_csv\n",
    "def load_required_data(path, required_columns):\n",
    "    dataframe = pd.read_json(path, lines=True)\n",
    "    dataframe = dataframe[required_columns]\n",
    "    return dataframe, dataframe.values\n",
    "\n",
    "train_df, values = load_required_data(filename, [\"asin\", \"reviewerID\", \"overall\",\"reviewText\", \"unixReviewTime\"])\n",
    "\n",
    "print \"Data loaded\"\n",
    "\n",
    "#sort by reviewerID\n",
    "train_df.sort_values(by=['reviewerID'],inplace=True)\n",
    "\n",
    "#cut the data \n",
    "train_df = train_df[start_index:end_index]\n",
    "\n",
    "print \"Data cut\"\n",
    "\n",
    "#check that the last user has enough reviews\n",
    "last_user_id = train_df.iloc[-1][\"reviewerID\"]\n",
    "i=-1\n",
    "index_list=[]\n",
    "\n",
    "while i>-1*(k+4) and train_df.iloc[i]['reviewerID'] == last_user_id:\n",
    "    index_list.append(train_df.iloc[i].name)\n",
    "    i-=1\n",
    "\n",
    "if len(index_list)<k+3:\n",
    "    train_df = train_df.drop(index_list).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#sort by items\n",
    "train_df.sort_values(by=['asin'],inplace=True)\n",
    "\n",
    "#remove items with <m entries\n",
    "index_list=[] # holds the indices of the current item\n",
    "last_item_id = 'undef' #first asin\n",
    "drop_list=[] # holds indices of all rows to be removed\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    if row['asin'] != last_item_id:\n",
    "        if len(index_list)<m:\n",
    "            drop_list.extend(index_list)\n",
    "        index_list=[]\n",
    "        last_item_id = row['asin']\n",
    "    index_list.append(index)\n",
    "    \n",
    "train_df = train_df.drop(drop_list).reset_index(drop=True)\n",
    "\n",
    "print \"Items with too few entries removed\"\n",
    "\n",
    "#sort by reviewerID again\n",
    "train_df.sort_values(by=['reviewerID'],inplace=True)\n",
    "\n",
    "last_user = 'undef' #first reviewerID\n",
    "row_dicts = []\n",
    "row_indices = []\n",
    "\n",
    "def markRowForTestSet(index, row):\n",
    "        row_dicts.append(row.to_dict()) # saving values for copying to train_df\n",
    "        row_indices.append(index) # saving indices for deletion\n",
    "\n",
    "#for each userid in train_df\n",
    "for index, row in train_df.iterrows():\n",
    "    if row['reviewerID'] != last_user: # first row for this user\n",
    "        markRowForTestSet(index, row)\n",
    "        n=k-1\n",
    "    elif n>0:\n",
    "        markRowForTestSet(index, row)\n",
    "        n-=1        \n",
    "    last_user = row['reviewerID']\n",
    "    \n",
    "test_df = pd.DataFrame.from_dict(row_dicts)\n",
    "\n",
    "print \"\\ntrain_df had\",len(train_df.reviewerID.unique()),\"unique reviewers and\",len(train_df.asin.unique()),\"unique items\"\n",
    "\n",
    "train_df = train_df.drop(row_indices).reset_index(drop=True)\n",
    "\n",
    "print \"\\ntrain_df now has\",len(train_df.reviewerID.unique()),\"unique reviewers and\",len(train_df.asin.unique()),\"unique items\"\n",
    "\n",
    "#remove extra user_ids and item_ids from the test set\n",
    "extra_user_ids = np.setdiff1d(test_df[\"reviewerID\"].unique(),train_df[\"reviewerID\"].unique())\n",
    "test_df = test_df[~test_df['reviewerID'].isin(extra_user_ids)]\n",
    "\n",
    "extra_item_ids = np.setdiff1d(test_df[\"asin\"].unique(),train_df[\"asin\"].unique())\n",
    "test_df = test_df[~test_df['asin'].isin(extra_item_ids)]\n",
    "\n",
    "print \"train_df now has \",len(train_df),\"reviews left\"\n",
    "print \"\\ntest_df has\",len(test_df.reviewerID.unique()),\"unique reviewers and\",len(test_df.asin.unique()),\"unique items\"\n",
    "print \"test_df now has \",len(test_df),\"reviews\"\n",
    "\n",
    "def writeDFtoVotesFile(df,test):\n",
    "    if test: output_file = open('test.votes', 'w')\n",
    "    else : output_file = open('train.votes', 'w')\n",
    "    for index,row in df.iterrows():\n",
    "        output_file.write(row[\"reviewerID\"] + ' ' + row[\"asin\"]+ ' ' + str(row[\"overall\"]) + ' ' + str(row[\"unixReviewTime\"]) + ' ' + str(len(row[\"reviewText\"].split())) + ' ' + row[\"reviewText\"] + '\\n')\n",
    "    output_file.close()\n",
    "\n",
    "#write to json files\n",
    "if (jsonFile):\n",
    "    test_df.to_json(\"test.json\",\n",
    "               orient=\"records\", lines=True)    \n",
    "    train_df.to_json(\"train.json\",\n",
    "               orient=\"records\", lines=True)\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    writeDFtoVotesFile(test_df,True)\n",
    "    writeDFtoVotesFile(train_df,False)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check how many users are in test but not train:\n",
    "np.setdiff1d(test_df[\"reviewerID\"].unique(),train_df[\"reviewerID\"].unique()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check how many items are in test but not train:\n",
    "np.setdiff1d(test_df[\"asin\"].unique(),train_df[\"asin\"].unique()).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
